{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Lit GPT"
      ],
      "metadata": {
        "id": "vWzCJYzdfQdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'litgpt[all] @ git+https://github.com/Lightning-AI/litgpt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y3FKcu3ZMqwS",
        "outputId": "81924ccf-d361-48c5-b0b2-a9fac7876f88"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litgpt[all]@ git+https://github.com/Lightning-AI/litgpt\n",
            "  Cloning https://github.com/Lightning-AI/litgpt to /tmp/pip-install-5rqxq934/litgpt_c322ea948efc46159bbe1e15c6a99517\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Lightning-AI/litgpt /tmp/pip-install-5rqxq934/litgpt_c322ea948efc46159bbe1e15c6a99517\n",
            "  Resolved https://github.com/Lightning-AI/litgpt to commit 22bed0828411205d4eb3825c67c1be9133324660\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lightning@ git+https://github.com/Lightning-AI/lightning@75553845c6bbcc305fbae38a46ef4e532e4ac85a (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Cloning https://github.com/Lightning-AI/lightning (to revision 75553845c6bbcc305fbae38a46ef4e532e4ac85a) to /tmp/pip-install-5rqxq934/lightning_2de1d92c99b940febabde6495212acfa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Lightning-AI/lightning /tmp/pip-install-5rqxq934/lightning_2de1d92c99b940febabde6495212acfa\n",
            "  Running command git rev-parse -q --verify 'sha^75553845c6bbcc305fbae38a46ef4e532e4ac85a'\n",
            "  Running command git fetch -q https://github.com/Lightning-AI/lightning 75553845c6bbcc305fbae38a46ef4e532e4ac85a\n",
            "  Running command git checkout -q 75553845c6bbcc305fbae38a46ef4e532e4ac85a\n",
            "  Resolved https://github.com/Lightning-AI/lightning to commit 75553845c6bbcc305fbae38a46ef4e532e4ac85a\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Encountered 22 file(s) that should have been pointers, but weren't:\n",
            "        .notebooks/course_UvA-DL/01-introduction-to-pytorch.ipynb\n",
            "        .notebooks/course_UvA-DL/02-activation-functions.ipynb\n",
            "        .notebooks/course_UvA-DL/03-initialization-and-optimization.ipynb\n",
            "        .notebooks/course_UvA-DL/04-inception-resnet-densenet.ipynb\n",
            "        .notebooks/course_UvA-DL/05-transformers-and-MH-attention.ipynb\n",
            "        .notebooks/course_UvA-DL/06-graph-neural-networks.ipynb\n",
            "        .notebooks/course_UvA-DL/07-deep-energy-based-generative-models.ipynb\n",
            "        .notebooks/course_UvA-DL/08-deep-autoencoders.ipynb\n",
            "        .notebooks/course_UvA-DL/09-normalizing-flows.ipynb\n",
            "        .notebooks/course_UvA-DL/10-autoregressive-image-modeling.ipynb\n",
            "        .notebooks/course_UvA-DL/11-vision-transformer.ipynb\n",
            "        .notebooks/flash_tutorials/electricity_forecasting.ipynb\n",
            "        .notebooks/flash_tutorials/image_classification.ipynb\n",
            "        .notebooks/flash_tutorials/tabular_classification.ipynb\n",
            "        .notebooks/flash_tutorials/text_classification.ipynb\n",
            "        .notebooks/lightning_examples/cifar10-baseline.ipynb\n",
            "        .notebooks/lightning_examples/datamodules.ipynb\n",
            "        .notebooks/lightning_examples/finetuning-scheduler.ipynb\n",
            "        .notebooks/lightning_examples/warp-drive.ipynb\n",
            "        .notebooks/templates/img-classify.ipynb\n",
            "        .notebooks/templates/simple.ipynb\n",
            "        .notebooks/templates/titanic.ipynb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonargparse[signatures]@ git+https://github.com/omni-us/jsonargparse (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Cloning https://github.com/omni-us/jsonargparse to /tmp/pip-install-5rqxq934/jsonargparse_ba092013fba7494cb29b4a28c5d0b5c0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/omni-us/jsonargparse /tmp/pip-install-5rqxq934/jsonargparse_ba092013fba7494cb29b4a28c5d0b5c0\n",
            "  Resolved https://github.com/omni-us/jsonargparse to commit bb83fdc76546743ad0e4e7012715febd965f34ac\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Cloning https://github.com/EleutherAI/lm-evaluation-harness.git (to revision 115206dc89dad67b8b) to /tmp/pip-install-5rqxq934/lm-eval_b60f7851edb44618a65bc18f3fed1e8a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/lm-evaluation-harness.git /tmp/pip-install-5rqxq934/lm-eval_b60f7851edb44618a65bc18f3fed1e8a\n",
            "\u001b[33m  WARNING: Did not find branch or tag '115206dc89dad67b8b', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running command git checkout -q 115206dc89dad67b8b\n",
            "  Resolved https://github.com/EleutherAI/lm-evaluation-harness.git to commit 115206dc89dad67b8b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.2.1+cu121)\n",
            "Collecting bitsandbytes==0.42.0 (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.1.99)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.15.2)\n",
            "Collecting datasets (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.31.0)\n",
            "Collecting litdata (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading litdata-0.2.2-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.5.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (14.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.15.2)\n",
            "Collecting torchmetrics (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub[hf_transfer]>=0.21.0 (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.42.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (24.0)\n",
            "Collecting hf-transfer>=0.1.4 (from huggingface-hub[hf_transfer]>=0.21.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading hf_transfer-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.25.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2024.2.2)\n",
            "Collecting docstring-parser>=0.15 (from jsonargparse[signatures]@ git+https://github.com/omni-us/jsonargparse->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]@ git+https://github.com/omni-us/jsonargparse->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading typeshed_client-2.5.1-py3-none-any.whl (606 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.1/606.1 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities<2.0,>=0.8.0 (from lightning@ git+https://github.com/Lightning-AI/lightning@75553845c6bbcc305fbae38a46ef4e532e4ac85a->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Collecting pytorch-lightning (from lightning@ git+https://github.com/Lightning-AI/lightning@75553845c6bbcc305fbae38a46ef4e532e4ac85a->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading pytorch_lightning-2.2.1-py3-none-any.whl (801 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-cloud==0.5.64 (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading lightning_cloud-0.5.64-py3-none-any.whl (928 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m928.4/928.4 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.17.1+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (9.4.0)\n",
            "Collecting viztracer (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading viztracer-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3[crt] (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading boto3-1.34.64-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (8.1.7)\n",
            "Collecting fastapi (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.3.0)\n",
            "Collecting python-multipart (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (13.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.16.0)\n",
            "Collecting uvicorn (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading uvicorn-0.28.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.7.0)\n",
            "Collecting einops (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (6.3.0)\n",
            "Collecting jsonlines (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.9.0)\n",
            "Collecting openai>=0.6.4 (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading openai-1.14.1-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf>=2.2 (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft>=0.2.0 (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading peft-0.9.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybind11>=2.6.2 (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycountry (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading pycountry-23.12.11-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytablewriter (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score>=0.0.4 (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu==1.5.0 (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.2.2)\n",
            "Collecting sqlitedict (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (4.38.2)\n",
            "Collecting accelerate>=0.17.1 (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu==1.5.0->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2023.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.17.1->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.17.1->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.4.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.2->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.8.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2023.12.25)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.1.5)\n",
            "Collecting botocore<1.35.0,>=1.34.64 (from boto3[crt]->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading botocore-1.34.64-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3[crt]->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3[crt]->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting DataProperty<2,>=1.0.1 (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading tcolorpy-0.1.4-py3-none-any.whl (7.9 kB)\n",
            "Collecting typepy[datetime]<2,>=1.3.2 (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.3.0)\n",
            "Collecting colorama (from tqdm-multiprocess->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting objprint>0.1.3 (from viztracer->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading objprint-0.2.3-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.2.0)\n",
            "Collecting awscrt==0.19.19 (from botocore<1.35.0,>=1.34.64->boto3[crt]->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading awscrt-0.19.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (5.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.5.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.16.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.2.2)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.1.2)\n",
            "Building wheels for collected packages: lightning, litgpt, lm-eval, antlr4-python3-runtime, rouge-score, jsonargparse, sqlitedict\n",
            "  Building wheel for lightning (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightning: filename=lightning-2.3.0.dev0-py3-none-any.whl size=1984731 sha256=b923f722acc6e1a0175a568c47812ac0721fa419bf0845ed4feb849fdfc944c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/ef/4d/9337e021b92f259eac51c4f9dc7b879bdbcd801652d6d2584b\n",
            "  Building wheel for litgpt (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for litgpt: filename=litgpt-0.2.0-py3-none-any.whl size=136388 sha256=9f0ef439dd04fad25add7f97b43b4f2c064c283fe2715007d847c481d9391490\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p228t7kf/wheels/e1/35/84/dd27bf19233f92182da0cb9b138645406f0c7a780128f1beab\n",
            "  Building wheel for lm-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lm-eval: filename=lm_eval-0.3.0-py3-none-any.whl size=2660364 sha256=c356def1e036a1584fdc5bc5c17a83d8da9d9ddb5e1438d6397e9fbdd6c5be7e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p228t7kf/wheels/86/79/19/5a166a8deb16d3c4826645e1b020d97d2d29947255481606d9\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=945c75e87b62ba8c7aec2e93e8932eb630131374460bd860d61dad52bad4ca1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=ada70fcf2444daa8f05673937fc811aa94facfc872ce631f4d8fa1b227f0e689\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for jsonargparse (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonargparse: filename=jsonargparse-4.27.6-py3-none-any.whl size=192190 sha256=4506b068b550c0e6629a2a624e3c9ef95c7a8f3885d734464e0af8733723d8e3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p228t7kf/wheels/6d/66/f2/e665a6959b15bddcbb4ce15e653c6822f5003c415f85b74e5e\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=c77c0a46f3ca1c34d757a314294223b155f623f90d120cc085a7c19ec4fe5686\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "Successfully built lightning litgpt lm-eval antlr4-python3-runtime rouge-score jsonargparse sqlitedict\n",
            "Installing collected packages: sqlitedict, antlr4-python3-runtime, zstandard, xxhash, typeshed-client, tcolorpy, python-multipart, pycountry, pybind11, portalocker, pathvalidate, omegaconf, objprint, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mbstrdecoder, lightning-utilities, jsonlines, jsonargparse, jmespath, hf-transfer, h11, einops, docstring-parser, dill, colorama, awscrt, viztracer, uvicorn, typepy, tqdm-multiprocess, starlette, sacrebleu, rouge-score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, httpcore, botocore, bitsandbytes, s3transfer, nvidia-cusolver-cu12, httpx, fastapi, openai, datasets, DataProperty, boto3, torchmetrics, tabledata, lightning-cloud, accelerate, pytorch-lightning, pytablewriter, peft, litdata, lm-eval, lightning, litgpt\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed DataProperty-1.0.1 accelerate-0.28.0 antlr4-python3-runtime-4.9.3 awscrt-0.19.19 bitsandbytes-0.42.0 boto3-1.34.64 botocore-1.34.64 colorama-0.4.6 datasets-2.18.0 dill-0.3.8 docstring-parser-0.16 einops-0.7.0 fastapi-0.110.0 h11-0.14.0 hf-transfer-0.1.6 httpcore-1.0.4 httpx-0.27.0 huggingface-hub-0.21.4 jmespath-1.0.1 jsonargparse-4.27.6 jsonlines-4.0.0 lightning-2.3.0.dev0 lightning-cloud-0.5.64 lightning-utilities-0.10.1 litdata-0.2.2 litgpt-0.2.0 lm-eval-0.3.0 mbstrdecoder-1.1.3 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 objprint-0.2.3 omegaconf-2.3.0 openai-1.14.1 pathvalidate-3.2.0 peft-0.9.0 portalocker-2.8.2 pybind11-2.11.1 pycountry-23.12.11 pytablewriter-1.2.0 python-multipart-0.0.9 pytorch-lightning-2.2.1 rouge-score-0.1.2 s3transfer-0.10.1 sacrebleu-1.5.0 sqlitedict-2.1.0 starlette-0.36.3 tabledata-1.3.3 tcolorpy-0.1.4 torchmetrics-1.3.1 tqdm-multiprocess-0.0.11 typepy-1.3.2 typeshed-client-2.5.1 uvicorn-0.28.0 viztracer-0.16.2 xxhash-3.4.1 zstandard-0.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "501e371243854060bc22a1e8969d0120"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk2nMSs9e61a",
        "outputId": "2f02ebf9-41ea-4879-e83b-df26dd392b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lit-gpt'...\n",
            "remote: Enumerating objects: 7877, done.\u001b[K\n",
            "remote: Counting objects: 100% (3046/3046), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1129/1129), done.\u001b[K\n",
            "remote: Total 7877 (delta 2476), reused 2079 (delta 1907), pack-reused 4831\u001b[K\n",
            "Receiving objects: 100% (7877/7877), 3.05 MiB | 20.85 MiB/s, done.\n",
            "Resolving deltas: 100% (5559/5559), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Lightning-AI/lit-gpt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('lit-gpt')\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42B2BYEGfGip",
        "outputId": "66bfe9e3-cd6a-4200-8e3d-9e9de22e8eb0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lit-gpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e '.[all]'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGpTwMOmfKHN",
        "outputId": "61d2157f-9f07-41c1-fdaa-7cadf81da7f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/lit-gpt\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lightning@ git+https://github.com/Lightning-AI/lightning@75553845c6bbcc305fbae38a46ef4e532e4ac85a (from litgpt==0.2.0)\n",
            "  Using cached lightning-2.3.0.dev0-py3-none-any.whl\n",
            "Collecting jsonargparse[signatures]@ git+https://github.com/omni-us/jsonargparse (from litgpt==0.2.0)\n",
            "  Cloning https://github.com/omni-us/jsonargparse to /tmp/pip-install-x7408fvp/jsonargparse_dbf50da38727474d902af1a6f63f2916\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/omni-us/jsonargparse /tmp/pip-install-x7408fvp/jsonargparse_dbf50da38727474d902af1a6f63f2916\n",
            "  Resolved https://github.com/omni-us/jsonargparse to commit bb83fdc76546743ad0e4e7012715febd965f34ac\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b (from litgpt==0.2.0)\n",
            "  Cloning https://github.com/EleutherAI/lm-evaluation-harness.git (to revision 115206dc89dad67b8b) to /tmp/pip-install-x7408fvp/lm-eval_838bc4e5d1e24f64b9cd7ddbea26b54e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/lm-evaluation-harness.git /tmp/pip-install-x7408fvp/lm-eval_838bc4e5d1e24f64b9cd7ddbea26b54e\n",
            "\u001b[33m  WARNING: Did not find branch or tag '115206dc89dad67b8b', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running command git checkout -q 115206dc89dad67b8b\n",
            "  Resolved https://github.com/EleutherAI/lm-evaluation-harness.git to commit 115206dc89dad67b8b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (2.2.1+cu121)\n",
            "Requirement already satisfied: bitsandbytes==0.42.0 in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (0.42.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (0.1.99)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (0.15.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (2.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (2.31.0)\n",
            "Requirement already satisfied: litdata in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (0.2.2)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (0.22.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (1.5.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (14.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (2.15.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: huggingface-hub[hf_transfer]>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from litgpt==0.2.0) (0.22.0.dev0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.42.0->litgpt==0.2.0) (1.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt==0.2.0) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt==0.2.0) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt==0.2.0) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt==0.2.0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt==0.2.0) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt==0.2.0) (24.0)\n",
            "Requirement already satisfied: hf-transfer>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt==0.2.0) (0.1.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt==0.2.0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0->litgpt==0.2.0) (12.4.99)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt==0.2.0) (1.25.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt==0.2.0) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt==0.2.0) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt==0.2.0) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt==0.2.0) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt==0.2.0) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt==0.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt==0.2.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt==0.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt==0.2.0) (2024.2.2)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]@ git+https://github.com/omni-us/jsonargparse->litgpt==0.2.0) (0.16)\n",
            "Requirement already satisfied: typeshed-client>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]@ git+https://github.com/omni-us/jsonargparse->litgpt==0.2.0) (2.5.1)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning@ git+https://github.com/Lightning-AI/lightning@75553845c6bbcc305fbae38a46ef4e532e4ac85a->litgpt==0.2.0) (0.10.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning@ git+https://github.com/Lightning-AI/lightning@75553845c6bbcc305fbae38a46ef4e532e4ac85a->litgpt==0.2.0) (2.2.1)\n",
            "Requirement already satisfied: lightning-cloud==0.5.64 in /usr/local/lib/python3.10/dist-packages (from litdata->litgpt==0.2.0) (0.5.64)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from litdata->litgpt==0.2.0) (0.17.1+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from litdata->litgpt==0.2.0) (9.4.0)\n",
            "Requirement already satisfied: viztracer in /usr/local/lib/python3.10/dist-packages (from litdata->litgpt==0.2.0) (0.16.2)\n",
            "Requirement already satisfied: boto3[crt] in /usr/local/lib/python3.10/dist-packages (from litdata->litgpt==0.2.0) (1.34.64)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (8.1.7)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (0.110.0)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (2.3.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (0.0.9)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (13.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (1.16.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (0.28.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (1.7.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (6.3.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (4.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (2.9.0)\n",
            "Requirement already satisfied: openai>=0.6.4 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.14.1)\n",
            "Requirement already satisfied: omegaconf>=2.2 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (2.3.0)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.9.0)\n",
            "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (2.11.1)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (23.12.11)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.2.0)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu==1.5.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.2.2)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (2.1.0)\n",
            "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.0.11)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (4.38.2)\n",
            "Requirement already satisfied: accelerate>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.28.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu==1.5.0->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->litgpt==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->litgpt==0.2.0) (2023.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt==0.2.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt==0.2.0) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt==0.2.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt==0.2.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt==0.2.0) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt==0.2.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt==0.2.0) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt==0.2.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt==0.2.0) (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.17.1->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.17.1->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt==0.2.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt==0.2.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt==0.2.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt==0.2.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt==0.2.0) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->litgpt==0.2.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->litgpt==0.2.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->litgpt==0.2.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->litgpt==0.2.0) (1.4.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.2->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (4.9.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (3.8.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (3.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (2023.12.25)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->litgpt==0.2.0) (2.1.5)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.64 in /usr/local/lib/python3.10/dist-packages (from boto3[crt]->litdata->litgpt==0.2.0) (1.34.64)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3[crt]->litdata->litgpt==0.2.0) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3[crt]->litdata->litgpt==0.2.0) (0.10.1)\n",
            "Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.0.1)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.1.3)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (3.2.0)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.3.3)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.1.4)\n",
            "Requirement already satisfied: typepy[datetime]<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.3.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0->litgpt==0.2.0) (1.3.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from tqdm-multiprocess->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.4.6)\n",
            "Requirement already satisfied: objprint>0.1.3 in /usr/local/lib/python3.10/dist-packages (from viztracer->litdata->litgpt==0.2.0) (0.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.2.0)\n",
            "Requirement already satisfied: awscrt==0.19.19 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.64->boto3[crt]->litdata->litgpt==0.2.0) (0.19.19)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.14.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->litgpt==0.2.0) (0.5.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=0.6.4->lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness.git@115206dc89dad67b8b->litgpt==0.2.0) (2.16.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->litgpt==0.2.0) (3.2.2)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (0.36.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->lightning-cloud==0.5.64->litdata->litgpt==0.2.0) (0.1.2)\n",
            "Building wheels for collected packages: litgpt\n",
            "  Building editable for litgpt (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for litgpt: filename=litgpt-0.2.0-0.editable-py3-none-any.whl size=16383 sha256=d81bb541b3d21e8d5836b21db4fc90c9baa3433dad40f18bc48a26b70558f64f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0rbba9rm/wheels/95/0e/15/5d3b7a1fe5d5aa0c1dbd929d4fe1086efa14cab0f839fbf582\n",
            "Successfully built litgpt\n",
            "Installing collected packages: litgpt\n",
            "  Attempting uninstall: litgpt\n",
            "    Found existing installation: litgpt 0.2.0\n",
            "    Uninstalling litgpt-0.2.0:\n",
            "      Successfully uninstalled litgpt-0.2.0\n",
            "Successfully installed litgpt-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'huggingface_hub[hf_transfer] @ git+https://github.com/huggingface/huggingface_hub'\n",
        "\n",
        "!python litgpt/scripts/download.py --repo_id mistralai/Mistral-7B-Instruct-v0.2\n",
        "!python litgpt/scripts/convert_hf_checkpoint.py --checkpoint_dir checkpoints/mistralai/Mistral-7B-Instruct-v0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyc47J5tfNNO",
        "outputId": "5f2ba628-b0e2-48f0-b86a-57e1f18958c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub\n",
            "  Cloning https://github.com/huggingface/huggingface_hub to /tmp/pip-install-txmrl33w/huggingface-hub_03ffc68446a547baae067005b22bae15\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/huggingface_hub /tmp/pip-install-txmrl33w/huggingface-hub_03ffc68446a547baae067005b22bae15\n",
            "  Resolved https://github.com/huggingface/huggingface_hub to commit cdd5289bcc732454b7f89976b602c2ba580a8283\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (24.0)\n",
            "Requirement already satisfied: hf-transfer>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (0.1.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[hf_transfer]@ git+https://github.com/huggingface/huggingface_hub) (2024.2.2)\n",
            "Setting HF_HUB_ENABLE_HF_TRANSFER=1\n",
            "config.json: 100% 596/596 [00:00<00:00, 2.86MB/s]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 712kB/s]\n",
            "pytorch_model-00001-of-00003.bin: 100% 4.94G/4.94G [00:37<00:00, 131MB/s] \n",
            "pytorch_model-00002-of-00003.bin: 100% 5.00G/5.00G [00:37<00:00, 132MB/s]\n",
            "pytorch_model-00003-of-00003.bin: 100% 5.06G/5.06G [00:31<00:00, 159MB/s] \n",
            "pytorch_model.bin.index.json: 100% 23.9k/23.9k [00:00<00:00, 55.8MB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 10.5MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 32.5MB/s]\n",
            "tokenizer_config.json: 100% 1.46k/1.46k [00:00<00:00, 10.8MB/s]\n",
            "Converting checkpoint files to LitGPT format.\n",
            "Processing checkpoints/mistralai/Mistral-7B-Instruct-v0.2/pytorch_model-00001-of-00003.bin\n",
            "Loading 'model.embed_tokens.weight' into RAM\n",
            "Loading 'model.layers.0.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.0.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.0.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.0.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.0.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.0.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.1.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.1.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.1.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.1.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.1.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.1.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.2.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.2.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.2.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.2.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.2.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.2.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.3.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.3.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.3.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.3.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.3.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.3.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.4.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.4.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.4.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.4.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.4.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.4.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.5.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.5.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.5.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.5.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.5.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.5.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.6.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.6.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.6.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.6.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.6.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.6.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.7.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.7.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.7.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.7.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.7.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.7.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.8.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.8.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.8.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.8.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.8.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.8.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.9.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.9.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.9.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.9.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.9.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.9.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.10.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.10.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.10.mlp.up_proj.weight' into RAM\n",
            "Loading 'layer 0 q' into RAM\n",
            "Loading 'layer 0 k' into RAM\n",
            "Loading 'layer 0 v' into RAM\n",
            "Loading 'layer 1 q' into RAM\n",
            "Loading 'layer 1 k' into RAM\n",
            "Loading 'layer 1 v' into RAM\n",
            "Loading 'layer 2 q' into RAM\n",
            "Loading 'layer 2 k' into RAM\n",
            "Loading 'layer 2 v' into RAM\n",
            "Loading 'layer 3 q' into RAM\n",
            "Loading 'layer 3 k' into RAM\n",
            "Loading 'layer 3 v' into RAM\n",
            "Loading 'layer 4 q' into RAM\n",
            "Loading 'layer 4 k' into RAM\n",
            "Loading 'layer 4 v' into RAM\n",
            "Loading 'layer 5 q' into RAM\n",
            "Loading 'layer 5 k' into RAM\n",
            "Loading 'layer 5 v' into RAM\n",
            "Loading 'layer 6 q' into RAM\n",
            "Loading 'layer 6 k' into RAM\n",
            "Loading 'layer 6 v' into RAM\n",
            "Loading 'layer 7 q' into RAM\n",
            "Loading 'layer 7 k' into RAM\n",
            "Loading 'layer 7 v' into RAM\n",
            "Loading 'layer 8 q' into RAM\n",
            "Loading 'layer 8 k' into RAM\n",
            "Loading 'layer 8 v' into RAM\n",
            "Loading 'layer 9 q' into RAM\n",
            "Loading 'layer 9 k' into RAM\n",
            "Loading 'layer 9 v' into RAM\n",
            "Loading 'layer 10 q' into RAM\n",
            "Loading 'layer 10 k' into RAM\n",
            "Loading 'layer 10 v' into RAM\n",
            "Processing checkpoints/mistralai/Mistral-7B-Instruct-v0.2/pytorch_model-00002-of-00003.bin\n",
            "Loading 'model.layers.10.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.10.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.10.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.11.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.11.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.11.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.11.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.11.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.11.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.12.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.12.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.12.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.12.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.12.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.12.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.13.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.13.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.13.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.13.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.13.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.13.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.14.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.14.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.14.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.14.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.14.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.14.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.15.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.15.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.15.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.15.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.15.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.15.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.16.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.16.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.16.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.16.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.16.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.16.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.17.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.17.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.17.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.17.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.17.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.17.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.18.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.18.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.18.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.18.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.18.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.18.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.19.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.19.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.19.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.19.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.19.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.19.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.20.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.20.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.20.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.20.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.20.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.20.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.21.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.21.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.21.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.21.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.21.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.21.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.22.self_attn.o_proj.weight' into RAM\n",
            "Loading 'layer 11 q' into RAM\n",
            "Loading 'layer 11 k' into RAM\n",
            "Loading 'layer 11 v' into RAM\n",
            "Loading 'layer 12 q' into RAM\n",
            "Loading 'layer 12 k' into RAM\n",
            "Loading 'layer 12 v' into RAM\n",
            "Loading 'layer 13 q' into RAM\n",
            "Loading 'layer 13 k' into RAM\n",
            "Loading 'layer 13 v' into RAM\n",
            "Loading 'layer 14 q' into RAM\n",
            "Loading 'layer 14 k' into RAM\n",
            "Loading 'layer 14 v' into RAM\n",
            "Loading 'layer 15 q' into RAM\n",
            "Loading 'layer 15 k' into RAM\n",
            "Loading 'layer 15 v' into RAM\n",
            "Loading 'layer 16 q' into RAM\n",
            "Loading 'layer 16 k' into RAM\n",
            "Loading 'layer 16 v' into RAM\n",
            "Loading 'layer 17 q' into RAM\n",
            "Loading 'layer 17 k' into RAM\n",
            "Loading 'layer 17 v' into RAM\n",
            "Loading 'layer 18 q' into RAM\n",
            "Loading 'layer 18 k' into RAM\n",
            "Loading 'layer 18 v' into RAM\n",
            "Loading 'layer 19 q' into RAM\n",
            "Loading 'layer 19 k' into RAM\n",
            "Loading 'layer 19 v' into RAM\n",
            "Loading 'layer 20 q' into RAM\n",
            "Loading 'layer 20 k' into RAM\n",
            "Loading 'layer 20 v' into RAM\n",
            "Loading 'layer 21 q' into RAM\n",
            "Loading 'layer 21 k' into RAM\n",
            "Loading 'layer 21 v' into RAM\n",
            "Loading 'layer 22 q' into RAM\n",
            "Loading 'layer 22 k' into RAM\n",
            "Loading 'layer 22 v' into RAM\n",
            "Processing checkpoints/mistralai/Mistral-7B-Instruct-v0.2/pytorch_model-00003-of-00003.bin\n",
            "Loading 'model.layers.22.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.22.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.22.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.22.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.22.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.23.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.23.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.23.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.23.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.23.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.23.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.24.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.24.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.24.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.24.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.24.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.24.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.25.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.25.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.25.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.25.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.25.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.25.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.26.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.26.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.26.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.26.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.26.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.26.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.27.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.27.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.27.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.27.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.27.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.27.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.28.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.28.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.28.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.28.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.28.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.28.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.29.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.29.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.29.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.29.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.29.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.29.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.30.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.30.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.30.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.30.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.30.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.30.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.31.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.31.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.31.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.31.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.31.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.31.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.norm.weight' into RAM\n",
            "Loading 'lm_head.weight' into RAM\n",
            "Loading 'layer 23 q' into RAM\n",
            "Loading 'layer 23 k' into RAM\n",
            "Loading 'layer 23 v' into RAM\n",
            "Loading 'layer 24 q' into RAM\n",
            "Loading 'layer 24 k' into RAM\n",
            "Loading 'layer 24 v' into RAM\n",
            "Loading 'layer 25 q' into RAM\n",
            "Loading 'layer 25 k' into RAM\n",
            "Loading 'layer 25 v' into RAM\n",
            "Loading 'layer 26 q' into RAM\n",
            "Loading 'layer 26 k' into RAM\n",
            "Loading 'layer 26 v' into RAM\n",
            "Loading 'layer 27 q' into RAM\n",
            "Loading 'layer 27 k' into RAM\n",
            "Loading 'layer 27 v' into RAM\n",
            "Loading 'layer 28 q' into RAM\n",
            "Loading 'layer 28 k' into RAM\n",
            "Loading 'layer 28 v' into RAM\n",
            "Loading 'layer 29 q' into RAM\n",
            "Loading 'layer 29 k' into RAM\n",
            "Loading 'layer 29 v' into RAM\n",
            "Loading 'layer 30 q' into RAM\n",
            "Loading 'layer 30 k' into RAM\n",
            "Loading 'layer 30 v' into RAM\n",
            "Loading 'layer 31 q' into RAM\n",
            "Loading 'layer 31 k' into RAM\n",
            "Loading 'layer 31 v' into RAM\n",
            "Saving converted checkpoint\n",
            "Processing checkpoints/mistralai/Mistral-7B-Instruct-v0.2/pytorch_model-00001-of-00003.bin\n",
            "Loading 'model.embed_tokens.weight' into RAM\n",
            "Loading 'model.layers.0.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.0.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.0.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.0.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.0.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.0.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.1.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.1.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.1.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.1.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.1.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.1.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.2.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.2.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.2.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.2.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.2.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.2.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.3.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.3.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.3.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.3.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.3.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.3.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.4.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.4.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.4.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.4.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.4.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.4.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.5.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.5.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.5.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.5.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.5.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.5.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.6.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.6.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.6.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.6.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.6.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.6.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.7.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.7.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.7.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.7.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.7.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.7.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.8.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.8.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.8.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.8.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.8.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.8.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.9.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.9.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.9.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.9.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.9.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.9.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.10.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.10.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.10.mlp.up_proj.weight' into RAM\n",
            "Loading 'layer 0 q' into RAM\n",
            "Loading 'layer 0 k' into RAM\n",
            "Loading 'layer 0 v' into RAM\n",
            "Loading 'layer 1 q' into RAM\n",
            "Loading 'layer 1 k' into RAM\n",
            "Loading 'layer 1 v' into RAM\n",
            "Loading 'layer 2 q' into RAM\n",
            "Loading 'layer 2 k' into RAM\n",
            "Loading 'layer 2 v' into RAM\n",
            "Loading 'layer 3 q' into RAM\n",
            "Loading 'layer 3 k' into RAM\n",
            "Loading 'layer 3 v' into RAM\n",
            "Loading 'layer 4 q' into RAM\n",
            "Loading 'layer 4 k' into RAM\n",
            "Loading 'layer 4 v' into RAM\n",
            "Loading 'layer 5 q' into RAM\n",
            "Loading 'layer 5 k' into RAM\n",
            "Loading 'layer 5 v' into RAM\n",
            "Loading 'layer 6 q' into RAM\n",
            "Loading 'layer 6 k' into RAM\n",
            "Loading 'layer 6 v' into RAM\n",
            "Loading 'layer 7 q' into RAM\n",
            "Loading 'layer 7 k' into RAM\n",
            "Loading 'layer 7 v' into RAM\n",
            "Loading 'layer 8 q' into RAM\n",
            "Loading 'layer 8 k' into RAM\n",
            "Loading 'layer 8 v' into RAM\n",
            "Loading 'layer 9 q' into RAM\n",
            "Loading 'layer 9 k' into RAM\n",
            "Loading 'layer 9 v' into RAM\n",
            "Loading 'layer 10 q' into RAM\n",
            "Loading 'layer 10 k' into RAM\n",
            "Loading 'layer 10 v' into RAM\n",
            "Processing checkpoints/mistralai/Mistral-7B-Instruct-v0.2/pytorch_model-00002-of-00003.bin\n",
            "Loading 'model.layers.10.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.10.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.10.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.11.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.11.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.11.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.11.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.11.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.11.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.12.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.12.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.12.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.12.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.12.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.12.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.13.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.13.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.13.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.13.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.13.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.13.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.14.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.14.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.14.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.14.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.14.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.14.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.15.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.15.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.15.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.15.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.15.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.15.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.16.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.16.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.16.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.16.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.16.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.16.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.17.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.17.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.17.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.17.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.17.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.17.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.18.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.18.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.18.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.18.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.18.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.18.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.19.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.19.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.19.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.19.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.19.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.19.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.20.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.20.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.20.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.20.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.20.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.20.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.21.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.21.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.21.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.21.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.21.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.21.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.22.self_attn.o_proj.weight' into RAM\n",
            "Loading 'layer 11 q' into RAM\n",
            "Loading 'layer 11 k' into RAM\n",
            "Loading 'layer 11 v' into RAM\n",
            "Loading 'layer 12 q' into RAM\n",
            "Loading 'layer 12 k' into RAM\n",
            "Loading 'layer 12 v' into RAM\n",
            "Loading 'layer 13 q' into RAM\n",
            "Loading 'layer 13 k' into RAM\n",
            "Loading 'layer 13 v' into RAM\n",
            "Loading 'layer 14 q' into RAM\n",
            "Loading 'layer 14 k' into RAM\n",
            "Loading 'layer 14 v' into RAM\n",
            "Loading 'layer 15 q' into RAM\n",
            "Loading 'layer 15 k' into RAM\n",
            "Loading 'layer 15 v' into RAM\n",
            "Loading 'layer 16 q' into RAM\n",
            "Loading 'layer 16 k' into RAM\n",
            "Loading 'layer 16 v' into RAM\n",
            "Loading 'layer 17 q' into RAM\n",
            "Loading 'layer 17 k' into RAM\n",
            "Loading 'layer 17 v' into RAM\n",
            "Loading 'layer 18 q' into RAM\n",
            "Loading 'layer 18 k' into RAM\n",
            "Loading 'layer 18 v' into RAM\n",
            "Loading 'layer 19 q' into RAM\n",
            "Loading 'layer 19 k' into RAM\n",
            "Loading 'layer 19 v' into RAM\n",
            "Loading 'layer 20 q' into RAM\n",
            "Loading 'layer 20 k' into RAM\n",
            "Loading 'layer 20 v' into RAM\n",
            "Loading 'layer 21 q' into RAM\n",
            "Loading 'layer 21 k' into RAM\n",
            "Loading 'layer 21 v' into RAM\n",
            "Loading 'layer 22 q' into RAM\n",
            "Loading 'layer 22 k' into RAM\n",
            "Loading 'layer 22 v' into RAM\n",
            "Processing checkpoints/mistralai/Mistral-7B-Instruct-v0.2/pytorch_model-00003-of-00003.bin\n",
            "Loading 'model.layers.22.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.22.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.22.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.22.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.22.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.23.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.23.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.23.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.23.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.23.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.23.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.24.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.24.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.24.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.24.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.24.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.24.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.25.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.25.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.25.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.25.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.25.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.25.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.26.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.26.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.26.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.26.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.26.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.26.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.27.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.27.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.27.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.27.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.27.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.27.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.28.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.28.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.28.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.28.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.28.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.28.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.29.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.29.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.29.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.29.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.29.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.29.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.30.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.30.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.30.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.30.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.30.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.30.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.layers.31.self_attn.o_proj.weight' into RAM\n",
            "Loading 'model.layers.31.mlp.gate_proj.weight' into RAM\n",
            "Loading 'model.layers.31.mlp.up_proj.weight' into RAM\n",
            "Loading 'model.layers.31.mlp.down_proj.weight' into RAM\n",
            "Loading 'model.layers.31.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.31.post_attention_layernorm.weight' into RAM\n",
            "Loading 'model.norm.weight' into RAM\n",
            "Loading 'lm_head.weight' into RAM\n",
            "Loading 'layer 23 q' into RAM\n",
            "Loading 'layer 23 k' into RAM\n",
            "Loading 'layer 23 v' into RAM\n",
            "Loading 'layer 24 q' into RAM\n",
            "Loading 'layer 24 k' into RAM\n",
            "Loading 'layer 24 v' into RAM\n",
            "Loading 'layer 25 q' into RAM\n",
            "Loading 'layer 25 k' into RAM\n",
            "Loading 'layer 25 v' into RAM\n",
            "Loading 'layer 26 q' into RAM\n",
            "Loading 'layer 26 k' into RAM\n",
            "Loading 'layer 26 v' into RAM\n",
            "Loading 'layer 27 q' into RAM\n",
            "Loading 'layer 27 k' into RAM\n",
            "Loading 'layer 27 v' into RAM\n",
            "Loading 'layer 28 q' into RAM\n",
            "Loading 'layer 28 k' into RAM\n",
            "Loading 'layer 28 v' into RAM\n",
            "Loading 'layer 29 q' into RAM\n",
            "Loading 'layer 29 k' into RAM\n",
            "Loading 'layer 29 v' into RAM\n",
            "Loading 'layer 30 q' into RAM\n",
            "Loading 'layer 30 k' into RAM\n",
            "Loading 'layer 30 v' into RAM\n",
            "Loading 'layer 31 q' into RAM\n",
            "Loading 'layer 31 k' into RAM\n",
            "Loading 'layer 31 v' into RAM\n",
            "Saving converted checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python litgpt/generate/base.py --precision bf16-true --checkpoint_dir checkpoints/mistralai/Mistral-7B-Instruct-v0.2 --prompt \"Write me a full 12 bar blues progression in ABC notation.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qtl4xJePf-40",
        "outputId": "83c9b792-a742-4583-cca0-6426509b29de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model 'checkpoints/mistralai/Mistral-7B-Instruct-v0.2/lit_model.pth' with {'name': 'Mistral-7B-Instruct-v0.2', 'hf_config': {'name': 'Mistral-7B-Instruct-v0.2', 'org': 'mistralai'}, 'scale_embeddings': False, 'block_size': 32768, 'vocab_size': 32000, 'padding_multiple': 512, 'padded_vocab_size': 32000, 'n_layer': 32, 'n_head': 32, 'head_size': 128, 'n_embd': 4096, 'rotary_percentage': 1.0, 'parallel_residual': False, 'bias': False, 'lm_head_bias': False, 'n_query_groups': 8, 'shared_attention_norm': False, 'norm_class_name': 'RMSNorm', 'norm_eps': 1e-05, 'mlp_class_name': 'LLaMAMLP', 'gelu_approximate': 'none', 'intermediate_size': 14336, 'rope_condense_ratio': 1, 'rope_base': 10000, 'n_expert': 0, 'n_expert_per_token': 0, 'rope_n_elem': 128}\n",
            "Time to instantiate model: 0.41 seconds.\n",
            "Time to load the model weights: 77.08 seconds.\n",
            "Seed set to 1234\n",
            "<s>[INST] Write me a full 12 bar blues progression in ABC notation. [/INST] I'm an AI language model, not specifically designed to generate music in ABC notation. However, I can certainly provide you with a standard 12-bar blues progression in ABC notation form.\n",
            "\n",
            "Here's an example of a\n",
            "Time for inference 1: 3.28 sec total, 15.25 tokens/sec\n",
            "Memory used: 14.54 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Data"
      ],
      "metadata": {
        "id": "4RdeeuN9pfmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mkeohane01/JamSesh.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D_NKCG7OzJA",
        "outputId": "ff3ff0c7-c881-4976-fb64-0f1929e52690"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'JamSesh' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/prepare_mydata.py --destination_path data/mydata/"
      ],
      "metadata": {
        "id": "bcFeR9UJgMpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune Model"
      ],
      "metadata": {
        "id": "KzV_1VpFpiQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python litgpt/finetune/lora.py \\\n",
        "  --checkpoint_dir \"checkpoints/mistralai/Mistral-7B-Instruct-v0.2/\" \\\n",
        "  --precision bf16-true \\\n",
        "  --quantize bnb.nf4 \\\n",
        "  --data JSON \\\n",
        "  --data.json_path \"JamSesh/data/sft_data_string.json\" \\\n",
        "  --data.val_split_fraction 0.1 \\\n",
        "  --out_dir \"out/lora_weights/mistral7B-finetuned/\" \\\n",
        "  --train.micro_batch_size 1 \\\n",
        "  --train.global_batch_size 1 \\\n",
        "  --train.epochs 2"
      ],
      "metadata": {
        "id": "AuwLFkdqpj-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff70b56b-805f-4f28-8f88-69b38aa82765"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'checkpoint_dir': PosixPath('checkpoints/mistralai/Mistral-7B-Instruct-v0.2'),\n",
            " 'data': JSON(json_path=PosixPath('JamSesh/data/sft_data_string.json'),\n",
            "              mask_prompt=False,\n",
            "              val_split_fraction=0.1,\n",
            "              prompt_style=<litgpt.prompts.Alpaca object at 0x7db76cc679a0>,\n",
            "              ignore_index=-100,\n",
            "              seed=42,\n",
            "              num_workers=4),\n",
            " 'devices': 1,\n",
            " 'eval': EvalArgs(interval=100, max_new_tokens=100, max_iters=100),\n",
            " 'logger_name': 'csv',\n",
            " 'lora_alpha': 16,\n",
            " 'lora_dropout': 0.05,\n",
            " 'lora_head': False,\n",
            " 'lora_key': False,\n",
            " 'lora_mlp': False,\n",
            " 'lora_projection': False,\n",
            " 'lora_query': True,\n",
            " 'lora_r': 8,\n",
            " 'lora_value': True,\n",
            " 'out_dir': PosixPath('out/lora_weights/mistral7B-finetuned'),\n",
            " 'precision': 'bf16-true',\n",
            " 'quantize': 'bnb.nf4',\n",
            " 'seed': 1337,\n",
            " 'train': TrainArgs(save_interval=1000,\n",
            "                    log_interval=1,\n",
            "                    global_batch_size=1,\n",
            "                    micro_batch_size=1,\n",
            "                    lr_warmup_steps=100,\n",
            "                    epochs=2,\n",
            "                    max_tokens=None,\n",
            "                    max_steps=None,\n",
            "                    max_seq_length=None,\n",
            "                    tie_embeddings=None,\n",
            "                    learning_rate=0.0003,\n",
            "                    weight_decay=0.02,\n",
            "                    beta1=0.9,\n",
            "                    beta2=0.95,\n",
            "                    max_norm=None,\n",
            "                    min_lr=6e-05)}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Seed set to 1337\n",
            "Number of trainable parameters: 3,407,872\n",
            "Number of non trainable parameters: 7,241,732,096\n",
            "The longest sequence length in the train data is 696, the model's maximum sequence length is 696 and context length is 32768\n",
            "Validating ...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Recommend a movie for me to watch during the weekend and explain the reason.\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Recommend a movie for me to watch during the weekend and explain the reason.\n",
            "\n",
            "### Response:\n",
            "Based on your preference for action films, I would recommend \"John Wick: Chapter 3 – Parabellum\". The movie continues the story of the former assassin, John Wick, as he is excommunicado from the international assassins guild, the High Table. To survive, John Wick must confront old friends, make new alliances, and fight his way through the criminal underworld. The movie offers non-stop action, thrilling stunts, and impressive\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/throughput.py:587: 'Tesla V100-SXM2-16GB' does not support torch.bfloat16\n",
            "Missing logger folder: out/lora_weights/mistral7B-finetuned/logs/csv\n",
            "Epoch 1 | iter 1 step 1 | loss train: 2.205, val: n/a | iter time: 1440.55 ms (step)\n",
            "Epoch 1 | iter 2 step 2 | loss train: 2.028, val: n/a | iter time: 1224.26 ms (step)\n",
            "Epoch 1 | iter 3 step 3 | loss train: 1.968, val: n/a | iter time: 1418.22 ms (step)\n",
            "Epoch 1 | iter 4 step 4 | loss train: 1.816, val: n/a | iter time: 1420.81 ms (step)\n",
            "Epoch 1 | iter 5 step 5 | loss train: 2.740, val: n/a | iter time: 927.36 ms (step)\n",
            "Epoch 1 | iter 6 step 6 | loss train: 2.746, val: n/a | iter time: 1055.58 ms (step)\n",
            "Epoch 1 | iter 7 step 7 | loss train: 2.373, val: n/a | iter time: 1074.91 ms (step)\n",
            "Epoch 1 | iter 8 step 8 | loss train: 2.013, val: n/a | iter time: 1231.62 ms (step)\n",
            "Epoch 1 | iter 9 step 9 | loss train: 2.546, val: n/a | iter time: 1073.30 ms (step)\n",
            "Epoch 1 | iter 10 step 10 | loss train: 1.843, val: n/a | iter time: 1766.52 ms (step)\n",
            "Epoch 1 | iter 11 step 11 | loss train: 2.033, val: n/a | iter time: 1177.60 ms (step)\n",
            "Epoch 1 | iter 12 step 12 | loss train: 1.754, val: n/a | iter time: 1179.65 ms (step)\n",
            "Epoch 1 | iter 13 step 13 | loss train: 2.693, val: n/a | iter time: 924.65 ms (step)\n",
            "Epoch 1 | iter 14 step 14 | loss train: 1.873, val: n/a | iter time: 1413.48 ms (step)\n",
            "Epoch 1 | iter 15 step 15 | loss train: 1.986, val: n/a | iter time: 1180.35 ms (step)\n",
            "Epoch 1 | iter 16 step 16 | loss train: 1.654, val: n/a | iter time: 1418.10 ms (step)\n",
            "Epoch 1 | iter 17 step 17 | loss train: 1.780, val: n/a | iter time: 1419.03 ms (step)\n",
            "Epoch 1 | iter 18 step 18 | loss train: 1.611, val: n/a | iter time: 1601.49 ms (step)\n",
            "Epoch 1 | iter 19 step 19 | loss train: 1.650, val: n/a | iter time: 1433.66 ms (step)\n",
            "Epoch 1 | iter 20 step 20 | loss train: 1.463, val: n/a | iter time: 1224.38 ms (step)\n",
            "Epoch 1 | iter 21 step 21 | loss train: 1.229, val: n/a | iter time: 1742.28 ms (step)\n",
            "Epoch 1 | iter 22 step 22 | loss train: 1.831, val: n/a | iter time: 1060.97 ms (step)\n",
            "Epoch 1 | iter 23 step 23 | loss train: 1.475, val: n/a | iter time: 1080.78 ms (step)\n",
            "Epoch 1 | iter 24 step 24 | loss train: 1.316, val: n/a | iter time: 1415.18 ms (step)\n",
            "Epoch 1 | iter 25 step 25 | loss train: 1.696, val: n/a | iter time: 1056.70 ms (step)\n",
            "Epoch 1 | iter 26 step 26 | loss train: 1.577, val: n/a | iter time: 1175.57 ms (step)\n",
            "Epoch 1 | iter 27 step 27 | loss train: 1.428, val: n/a | iter time: 1061.50 ms (step)\n",
            "Epoch 1 | iter 28 step 28 | loss train: 1.211, val: n/a | iter time: 1246.22 ms (step)\n",
            "Epoch 1 | iter 29 step 29 | loss train: 1.182, val: n/a | iter time: 1728.72 ms (step)\n",
            "Epoch 1 | iter 30 step 30 | loss train: 1.235, val: n/a | iter time: 1227.92 ms (step)\n",
            "Epoch 1 | iter 31 step 31 | loss train: 1.523, val: n/a | iter time: 1077.25 ms (step)\n",
            "Epoch 1 | iter 32 step 32 | loss train: 1.158, val: n/a | iter time: 1227.26 ms (step)\n",
            "Epoch 1 | iter 33 step 33 | loss train: 1.074, val: n/a | iter time: 1413.98 ms (step)\n",
            "Epoch 1 | iter 34 step 34 | loss train: 1.155, val: n/a | iter time: 1179.52 ms (step)\n",
            "Epoch 1 | iter 35 step 35 | loss train: 1.330, val: n/a | iter time: 926.19 ms (step)\n",
            "Epoch 1 | iter 36 step 36 | loss train: 1.250, val: n/a | iter time: 1078.56 ms (step)\n",
            "Epoch 1 | iter 37 step 37 | loss train: 1.192, val: n/a | iter time: 928.76 ms (step)\n",
            "Epoch 1 | iter 38 step 38 | loss train: 0.803, val: n/a | iter time: 1194.16 ms (step)\n",
            "Epoch 1 | iter 39 step 39 | loss train: 0.763, val: n/a | iter time: 1242.00 ms (step)\n",
            "Epoch 1 | iter 40 step 40 | loss train: 1.010, val: n/a | iter time: 1077.18 ms (step)\n",
            "Epoch 1 | iter 41 step 41 | loss train: 0.773, val: n/a | iter time: 1224.32 ms (step)\n",
            "Epoch 1 | iter 42 step 42 | loss train: 0.997, val: n/a | iter time: 923.82 ms (step)\n",
            "Epoch 1 | iter 43 step 43 | loss train: 0.884, val: n/a | iter time: 925.71 ms (step)\n",
            "Epoch 1 | iter 44 step 44 | loss train: 0.613, val: n/a | iter time: 1180.02 ms (step)\n",
            "Epoch 1 | iter 45 step 45 | loss train: 0.776, val: n/a | iter time: 923.21 ms (step)\n",
            "Epoch 1 | iter 46 step 46 | loss train: 0.454, val: n/a | iter time: 1708.64 ms (step)\n",
            "Epoch 1 | iter 47 step 47 | loss train: 0.645, val: n/a | iter time: 1230.22 ms (step)\n",
            "Epoch 1 | iter 48 step 48 | loss train: 1.047, val: n/a | iter time: 1430.23 ms (step)\n",
            "Epoch 1 | iter 49 step 49 | loss train: 0.530, val: n/a | iter time: 941.57 ms (step)\n",
            "Epoch 1 | iter 50 step 50 | loss train: 0.639, val: n/a | iter time: 1599.21 ms (step)\n",
            "Epoch 1 | iter 51 step 51 | loss train: 0.486, val: n/a | iter time: 1230.23 ms (step)\n",
            "Epoch 1 | iter 52 step 52 | loss train: 0.711, val: n/a | iter time: 1056.47 ms (step)\n",
            "Epoch 1 | iter 53 step 53 | loss train: 0.603, val: n/a | iter time: 1602.78 ms (step)\n",
            "Epoch 1 | iter 54 step 54 | loss train: 0.562, val: n/a | iter time: 1076.85 ms (step)\n",
            "Epoch 1 | iter 55 step 55 | loss train: 0.558, val: n/a | iter time: 1230.38 ms (step)\n",
            "Epoch 1 | iter 56 step 56 | loss train: 0.622, val: n/a | iter time: 1419.37 ms (step)\n",
            "Epoch 1 | iter 57 step 57 | loss train: 0.451, val: n/a | iter time: 1180.11 ms (step)\n",
            "Epoch 1 | iter 58 step 58 | loss train: 0.605, val: n/a | iter time: 1100.27 ms (step)\n",
            "Epoch 1 | iter 59 step 59 | loss train: 0.688, val: n/a | iter time: 2433.99 ms (step)\n",
            "Epoch 1 | iter 60 step 60 | loss train: 0.698, val: n/a | iter time: 926.19 ms (step)\n",
            "Epoch 1 | iter 61 step 61 | loss train: 0.508, val: n/a | iter time: 1416.08 ms (step)\n",
            "Epoch 1 | iter 62 step 62 | loss train: 0.660, val: n/a | iter time: 1053.47 ms (step)\n",
            "Epoch 1 | iter 63 step 63 | loss train: 0.677, val: n/a | iter time: 1055.19 ms (step)\n",
            "Epoch 1 | iter 64 step 64 | loss train: 0.666, val: n/a | iter time: 1225.35 ms (step)\n",
            "Epoch 1 | iter 65 step 65 | loss train: 0.579, val: n/a | iter time: 1418.43 ms (step)\n",
            "Epoch 1 | iter 66 step 66 | loss train: 0.486, val: n/a | iter time: 1717.05 ms (step)\n",
            "Epoch 1 | iter 67 step 67 | loss train: 0.508, val: n/a | iter time: 1194.55 ms (step)\n",
            "Epoch 1 | iter 68 step 68 | loss train: 0.651, val: n/a | iter time: 1418.40 ms (step)\n",
            "Epoch 1 | iter 69 step 69 | loss train: 0.498, val: n/a | iter time: 1224.18 ms (step)\n",
            "Epoch 1 | iter 70 step 70 | loss train: 0.551, val: n/a | iter time: 1073.75 ms (step)\n",
            "Epoch 1 | iter 71 step 71 | loss train: 0.751, val: n/a | iter time: 1058.29 ms (step)\n",
            "Epoch 1 | iter 72 step 72 | loss train: 0.556, val: n/a | iter time: 1176.04 ms (step)\n",
            "Epoch 1 | iter 73 step 73 | loss train: 0.328, val: n/a | iter time: 1229.38 ms (step)\n",
            "Epoch 1 | iter 74 step 74 | loss train: 0.520, val: n/a | iter time: 1412.58 ms (step)\n",
            "Epoch 1 | iter 75 step 75 | loss train: 0.468, val: n/a | iter time: 1224.19 ms (step)\n",
            "Epoch 1 | iter 76 step 76 | loss train: 0.485, val: n/a | iter time: 1246.37 ms (step)\n",
            "Epoch 1 | iter 77 step 77 | loss train: 0.596, val: n/a | iter time: 1432.84 ms (step)\n",
            "Epoch 1 | iter 78 step 78 | loss train: 0.774, val: n/a | iter time: 1418.97 ms (step)\n",
            "Epoch 1 | iter 79 step 79 | loss train: 0.425, val: n/a | iter time: 1180.25 ms (step)\n",
            "Epoch 1 | iter 80 step 80 | loss train: 0.560, val: n/a | iter time: 1056.76 ms (step)\n",
            "Epoch 1 | iter 81 step 81 | loss train: 0.373, val: n/a | iter time: 1228.00 ms (step)\n",
            "Epoch 1 | iter 82 step 82 | loss train: 0.273, val: n/a | iter time: 1229.16 ms (step)\n",
            "Epoch 1 | iter 83 step 83 | loss train: 0.419, val: n/a | iter time: 1415.47 ms (step)\n",
            "Epoch 2 | iter 84 step 84 | loss train: 0.584, val: n/a | iter time: 1238.26 ms (step)\n",
            "Epoch 2 | iter 85 step 85 | loss train: 0.483, val: n/a | iter time: 1241.27 ms (step)\n",
            "Epoch 2 | iter 86 step 86 | loss train: 0.530, val: n/a | iter time: 1075.24 ms (step)\n",
            "Epoch 2 | iter 87 step 87 | loss train: 0.391, val: n/a | iter time: 1080.44 ms (step)\n",
            "Epoch 2 | iter 88 step 88 | loss train: 0.599, val: n/a | iter time: 1078.09 ms (step)\n",
            "Epoch 2 | iter 89 step 89 | loss train: 0.643, val: n/a | iter time: 1416.64 ms (step)\n",
            "Epoch 2 | iter 90 step 90 | loss train: 0.507, val: n/a | iter time: 1230.12 ms (step)\n",
            "Epoch 2 | iter 91 step 91 | loss train: 0.493, val: n/a | iter time: 1225.66 ms (step)\n",
            "Epoch 2 | iter 92 step 92 | loss train: 0.534, val: n/a | iter time: 1181.16 ms (step)\n",
            "Epoch 2 | iter 93 step 93 | loss train: 0.431, val: n/a | iter time: 1178.19 ms (step)\n",
            "Epoch 2 | iter 94 step 94 | loss train: 0.397, val: n/a | iter time: 1179.59 ms (step)\n",
            "Epoch 2 | iter 95 step 95 | loss train: 0.604, val: n/a | iter time: 1081.52 ms (step)\n",
            "Epoch 2 | iter 96 step 96 | loss train: 0.337, val: n/a | iter time: 1198.41 ms (step)\n",
            "Epoch 2 | iter 97 step 97 | loss train: 0.456, val: n/a | iter time: 951.14 ms (step)\n",
            "Epoch 2 | iter 98 step 98 | loss train: 0.691, val: n/a | iter time: 1174.51 ms (step)\n",
            "Epoch 2 | iter 99 step 99 | loss train: 0.405, val: n/a | iter time: 1079.56 ms (step)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "Epoch 2 | iter 100 step 100 | loss train: 0.473, val: n/a | iter time: 1611.66 ms (step)\n",
            "Validating ...\n",
            "Recommend a movie for me to watch during the weekend and explain the reason.\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Recommend a movie for me to watch during the weekend and explain the reason.\n",
            "\n",
            "### Response:\n",
            "Based on your preference for romantic comedies, I would recommend \"Crazy, Stupid, Love\" (2011). This film is a refreshing take on love, relationships, and the choices we make. The characters are relatable, the humor is sharp, and the romance is heartwarming. Enjoy your weekend and the movie!\n",
            "iter 100: val loss 0.5536, val time: 12548.25 ms\n",
            "Epoch 2 | iter 101 step 101 | loss train: 0.428, val: 0.554 | iter time: 1059.30 ms (step)\n",
            "Epoch 2 | iter 102 step 102 | loss train: 0.505, val: 0.554 | iter time: 1418.62 ms (step)\n",
            "Epoch 2 | iter 103 step 103 | loss train: 0.609, val: 0.554 | iter time: 1059.17 ms (step)\n",
            "Epoch 2 | iter 104 step 104 | loss train: 0.633, val: 0.554 | iter time: 1077.37 ms (step)\n",
            "Epoch 2 | iter 105 step 105 | loss train: 0.485, val: 0.554 | iter time: 1746.27 ms (step)\n",
            "Epoch 2 | iter 106 step 106 | loss train: 0.352, val: 0.554 | iter time: 1427.23 ms (step)\n",
            "Epoch 2 | iter 107 step 107 | loss train: 0.312, val: 0.554 | iter time: 1226.92 ms (step)\n",
            "Epoch 2 | iter 108 step 108 | loss train: 0.676, val: 0.554 | iter time: 1417.91 ms (step)\n",
            "Epoch 2 | iter 109 step 109 | loss train: 0.640, val: 0.554 | iter time: 925.08 ms (step)\n",
            "Epoch 2 | iter 110 step 110 | loss train: 0.388, val: 0.554 | iter time: 1227.96 ms (step)\n",
            "Epoch 2 | iter 111 step 111 | loss train: 0.503, val: 0.554 | iter time: 1420.07 ms (step)\n",
            "Epoch 2 | iter 112 step 112 | loss train: 0.292, val: 0.554 | iter time: 1413.75 ms (step)\n",
            "Epoch 2 | iter 113 step 113 | loss train: 0.614, val: 0.554 | iter time: 927.33 ms (step)\n",
            "Epoch 2 | iter 114 step 114 | loss train: 0.381, val: 0.554 | iter time: 1715.81 ms (step)\n",
            "Epoch 2 | iter 115 step 115 | loss train: 0.429, val: 0.554 | iter time: 1439.74 ms (step)\n",
            "Epoch 2 | iter 116 step 116 | loss train: 0.368, val: 0.554 | iter time: 1232.84 ms (step)\n",
            "Epoch 2 | iter 117 step 117 | loss train: 0.519, val: 0.554 | iter time: 924.28 ms (step)\n",
            "Epoch 2 | iter 118 step 118 | loss train: 0.290, val: 0.554 | iter time: 1707.62 ms (step)\n",
            "Epoch 2 | iter 119 step 119 | loss train: 0.507, val: 0.554 | iter time: 926.25 ms (step)\n",
            "Epoch 2 | iter 120 step 120 | loss train: 0.449, val: 0.554 | iter time: 1415.12 ms (step)\n",
            "Epoch 2 | iter 121 step 121 | loss train: 0.353, val: 0.554 | iter time: 1222.54 ms (step)\n",
            "Epoch 2 | iter 122 step 122 | loss train: 0.349, val: 0.554 | iter time: 1415.01 ms (step)\n",
            "Epoch 2 | iter 123 step 123 | loss train: 0.449, val: 0.554 | iter time: 1058.34 ms (step)\n",
            "Epoch 2 | iter 124 step 124 | loss train: 0.347, val: 0.554 | iter time: 1237.49 ms (step)\n",
            "Epoch 2 | iter 125 step 125 | loss train: 0.391, val: 0.554 | iter time: 1435.13 ms (step)\n",
            "Epoch 2 | iter 126 step 126 | loss train: 0.493, val: 0.554 | iter time: 1058.79 ms (step)\n",
            "Epoch 2 | iter 127 step 127 | loss train: 0.584, val: 0.554 | iter time: 925.74 ms (step)\n",
            "Epoch 2 | iter 128 step 128 | loss train: 0.467, val: 0.554 | iter time: 1056.64 ms (step)\n",
            "Epoch 2 | iter 129 step 129 | loss train: 0.584, val: 0.554 | iter time: 1722.88 ms (step)\n",
            "Epoch 2 | iter 130 step 130 | loss train: 0.581, val: 0.554 | iter time: 2422.26 ms (step)\n",
            "Epoch 2 | iter 131 step 131 | loss train: 0.456, val: 0.554 | iter time: 1227.07 ms (step)\n",
            "Epoch 2 | iter 132 step 132 | loss train: 0.338, val: 0.554 | iter time: 1419.87 ms (step)\n",
            "Epoch 2 | iter 133 step 133 | loss train: 0.426, val: 0.554 | iter time: 1244.85 ms (step)\n",
            "Epoch 2 | iter 134 step 134 | loss train: 0.294, val: 0.554 | iter time: 1200.45 ms (step)\n",
            "Epoch 2 | iter 135 step 135 | loss train: 0.638, val: 0.554 | iter time: 1059.94 ms (step)\n",
            "Epoch 2 | iter 136 step 136 | loss train: 0.486, val: 0.554 | iter time: 1229.76 ms (step)\n",
            "Epoch 2 | iter 137 step 137 | loss train: 0.460, val: 0.554 | iter time: 1602.84 ms (step)\n",
            "Epoch 2 | iter 138 step 138 | loss train: 0.370, val: 0.554 | iter time: 1175.73 ms (step)\n",
            "Epoch 2 | iter 139 step 139 | loss train: 0.423, val: 0.554 | iter time: 1074.72 ms (step)\n",
            "Epoch 2 | iter 140 step 140 | loss train: 0.582, val: 0.554 | iter time: 1226.93 ms (step)\n",
            "Epoch 2 | iter 141 step 141 | loss train: 0.400, val: 0.554 | iter time: 1420.54 ms (step)\n",
            "Epoch 2 | iter 142 step 142 | loss train: 0.578, val: 0.554 | iter time: 928.63 ms (step)\n",
            "Epoch 2 | iter 143 step 143 | loss train: 0.447, val: 0.554 | iter time: 1608.77 ms (step)\n",
            "Epoch 2 | iter 144 step 144 | loss train: 0.494, val: 0.554 | iter time: 1062.68 ms (step)\n",
            "Epoch 2 | iter 145 step 145 | loss train: 0.462, val: 0.554 | iter time: 1415.07 ms (step)\n",
            "Epoch 2 | iter 146 step 146 | loss train: 0.535, val: 0.554 | iter time: 1183.94 ms (step)\n",
            "Epoch 2 | iter 147 step 147 | loss train: 0.406, val: 0.554 | iter time: 1167.35 ms (step)\n",
            "Epoch 2 | iter 148 step 148 | loss train: 0.771, val: 0.554 | iter time: 1414.39 ms (step)\n",
            "Epoch 2 | iter 149 step 149 | loss train: 0.504, val: 0.554 | iter time: 926.48 ms (step)\n",
            "Epoch 2 | iter 150 step 150 | loss train: 0.517, val: 0.554 | iter time: 1184.08 ms (step)\n",
            "Epoch 2 | iter 151 step 151 | loss train: 0.441, val: 0.554 | iter time: 1056.42 ms (step)\n",
            "Epoch 2 | iter 152 step 152 | loss train: 0.361, val: 0.554 | iter time: 1079.86 ms (step)\n",
            "Epoch 2 | iter 153 step 153 | loss train: 0.369, val: 0.554 | iter time: 1245.42 ms (step)\n",
            "Epoch 2 | iter 154 step 154 | loss train: 0.174, val: 0.554 | iter time: 1245.62 ms (step)\n",
            "Epoch 2 | iter 155 step 155 | loss train: 0.350, val: 0.554 | iter time: 924.36 ms (step)\n",
            "Epoch 2 | iter 156 step 156 | loss train: 0.492, val: 0.554 | iter time: 1416.40 ms (step)\n",
            "Epoch 2 | iter 157 step 157 | loss train: 0.493, val: 0.554 | iter time: 1227.30 ms (step)\n",
            "Epoch 2 | iter 158 step 158 | loss train: 0.380, val: 0.554 | iter time: 1231.63 ms (step)\n",
            "Epoch 2 | iter 159 step 159 | loss train: 0.292, val: 0.554 | iter time: 1232.01 ms (step)\n",
            "Epoch 2 | iter 160 step 160 | loss train: 0.415, val: 0.554 | iter time: 1081.86 ms (step)\n",
            "Epoch 2 | iter 161 step 161 | loss train: 0.313, val: 0.554 | iter time: 1228.82 ms (step)\n",
            "Epoch 2 | iter 162 step 162 | loss train: 0.387, val: 0.554 | iter time: 1231.06 ms (step)\n",
            "Epoch 2 | iter 163 step 163 | loss train: 0.394, val: 0.554 | iter time: 1439.52 ms (step)\n",
            "Epoch 2 | iter 164 step 164 | loss train: 0.561, val: 0.554 | iter time: 1753.49 ms (step)\n",
            "Epoch 2 | iter 165 step 165 | loss train: 0.616, val: 0.554 | iter time: 1420.04 ms (step)\n",
            "Epoch 2 | iter 166 step 166 | loss train: 0.303, val: 0.554 | iter time: 1176.06 ms (step)\n",
            "Epoch 3 | iter 167 step 167 | loss train: 0.430, val: 0.554 | iter time: 1105.64 ms (step)\n",
            "Training time: 234.88s\n",
            "Memory used: 11.57 GB\n",
            "Saving LoRA weights to 'out/lora_weights/mistral7B-finetuned/final/lit_model.pth.lora'\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!litgpt generate base \\\n",
        "  --checkpoint_dir \"out/lora_weights/mistral7B-finetuned/final/\" \\\n",
        "  --prompt \"12 bar blues jam\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cxTYKwbi87L",
        "outputId": "2a25cc84-5a20-4b07-98d2-60a3a5718cf1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--checkpoint_dir '/content/lit-gpt/out/lora_weights/mistral7B-finetuned/final' is missing the files: ['lit_model.pth'].\n",
            "Find download instructions at https://github.com/Lightning-AI/litgpt/blob/main/tutorials\n",
            "\n",
            "You have downloaded locally:\n",
            " --checkpoint_dir '/content/lit-gpt/checkpoints/mistralai/Mistral-7B-Instruct-v0.2'\n",
            "\n",
            "See all download options by running:\n",
            " litgpt download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!litgpt merge_lora \\\n",
        " --checkpoint_dir \"out/lora_weights/mistral7B-finetuned/final/\" \\\n",
        " --pretrained_checkpoint_dir \"checkpoints/mistralai/Mistral-7B-Instruct-v0.2/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOuhMfoQjaZr",
        "outputId": "3272ae73-fe8d-4dec-bcaa-0fe942b8523d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r out/lora_weights/mistral7B-finetuned/final.zip out/lora_weights/mistral7B-finetuned/final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl3rrAc5plIa",
        "outputId": "6dccd85f-a09c-4a0f-efe9-4db882b96ccd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: out/lora_weights/mistral7B-finetuned/final/ (stored 0%)\n",
            "  adding: out/lora_weights/mistral7B-finetuned/final/prompt_style.yaml (stored 0%)\n",
            "  adding: out/lora_weights/mistral7B-finetuned/final/tokenizer_config.json (deflated 64%)\n",
            "  adding: out/lora_weights/mistral7B-finetuned/final/model_config.yaml (deflated 43%)\n",
            "  adding: out/lora_weights/mistral7B-finetuned/final/tokenizer.json (deflated 74%)\n",
            "  adding: out/lora_weights/mistral7B-finetuned/final/generation_config.json (deflated 20%)\n",
            "  adding: out/lora_weights/mistral7B-finetuned/final/lit_model.pth.lora (deflated 21%)\n",
            "  adding: out/lora_weights/mistral7B-finetuned/final/hyperparameters.yaml (deflated 45%)\n",
            "  adding: out/lora_weights/mistral7B-finetuned/final/tokenizer.model (deflated 55%)\n"
          ]
        }
      ]
    }
  ]
}